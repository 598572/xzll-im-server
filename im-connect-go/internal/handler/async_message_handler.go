package handler

import (
	"context"
	"sync"
	"sync/atomic"
	"time"

	"im-connect-go/internal/channel"
	"im-connect-go/internal/config"
	"im-connect-go/internal/metrics"

	"go.uber.org/zap"
)

// messageTaskPool å¯¹è±¡æ± ï¼ˆå¯¹æ ‡ Netty PooledByteBufAllocatorï¼‰
// å¤ç”¨ MessageTask å¯¹è±¡ï¼Œå‡å°‘ GC å‹åŠ›
var messageTaskPool = sync.Pool{
	New: func() interface{} {
		return &MessageTask{}
	},
}

// AsyncMessageHandler å¼‚æ­¥æ¶ˆæ¯å¤„ç†å™¨
// å¯¹æ ‡ Java çš„ ThreadPoolTaskExecutor å¤„ç†æ–¹å¼
type AsyncMessageHandler struct {
	config        *config.Config
	logger        *zap.Logger
	msgHandler    *MessageHandler
	metricsClient *metrics.Metrics

	// å¤„ç†é˜Ÿåˆ—
	queue      chan *MessageTask
	queueSize  int
	numWorkers int

	// å·¥ä½œåç¨‹
	workers []*MessageWorker

	// ç»Ÿè®¡
	processedCount int64
	droppedCount   int64
	queueMaxLength int
	failureCount   int64
	processingTime int64 // çº³ç§’

	// åœæ­¢ä¿¡å·
	stopChan chan struct{}
	wg       sync.WaitGroup
	mu       sync.RWMutex
}

// MessageTask æ¶ˆæ¯å¤„ç†ä»»åŠ¡
type MessageTask struct {
	UserID     string
	Connection channel.Connection
	Message    []byte
	Timestamp  time.Time
	RetryCount int
}

// MessageWorker æ¶ˆæ¯å¤„ç†å·¥ä½œåç¨‹
type MessageWorker struct {
	id      int
	queue   chan *MessageTask
	handler *MessageHandler
	logger  *zap.Logger
	metrics *metrics.Metrics
}

// NewAsyncMessageHandler åˆ›å»ºå¼‚æ­¥æ¶ˆæ¯å¤„ç†å™¨
func NewAsyncMessageHandler(
	cfg *config.Config,
	logger *zap.Logger,
	msgHandler *MessageHandler,
	queueSize int,
	numWorkers int,
) *AsyncMessageHandler {
	if queueSize <= 0 {
		queueSize = 10000
	}
	if numWorkers <= 0 {
		numWorkers = 16
	}

	handler := &AsyncMessageHandler{
		config:        cfg,
		logger:        logger,
		msgHandler:    msgHandler,
		metricsClient: metrics.GetMetrics(),
		queue:         make(chan *MessageTask, queueSize),
		queueSize:     queueSize,
		numWorkers:    numWorkers,
		workers:       make([]*MessageWorker, numWorkers),
		stopChan:      make(chan struct{}),
	}

	// å¯åŠ¨å·¥ä½œåç¨‹
	for i := 0; i < numWorkers; i++ {
		worker := &MessageWorker{
			id:      i,
			queue:   handler.queue,
			handler: msgHandler,
			logger:  logger,
			metrics: metrics.GetMetrics(),
		}
		handler.workers[i] = worker

		handler.wg.Add(1)
		go worker.run(&handler.wg, handler)
	}

	logger.Info("âœ… å¼‚æ­¥æ¶ˆæ¯å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ",
		zap.Int("queue_size", queueSize),
		zap.Int("num_workers", numWorkers),
	)

	return handler
}

// Submit æäº¤æ¶ˆæ¯å¤„ç†ä»»åŠ¡
func (h *AsyncMessageHandler) Submit(userID string, conn channel.Connection, message []byte) bool {
	// âœ… ä»å¯¹è±¡æ± è·å–ï¼ˆå¯¹æ ‡ Netty ctx.alloc().buffer()ï¼‰
	task := messageTaskPool.Get().(*MessageTask)
	task.UserID = userID
	task.Connection = conn
	task.Message = message
	task.Timestamp = time.Now()
	task.RetryCount = 0

	select {
	case h.queue <- task:
		// æ›´æ–°æœ€å¤§é˜Ÿåˆ—é•¿åº¦
		h.mu.Lock()
		currentLen := len(h.queue)
		if currentLen > h.queueMaxLength {
			h.queueMaxLength = currentLen
		}
		h.mu.Unlock()

		// è®°å½•ç›‘æ§æŒ‡æ ‡
		if h.metricsClient != nil {
			// h.metricsClient.RecordMessageQueued()
		}

		return true
	default:
		// é˜Ÿåˆ—æ»¡ï¼Œä¸¢å¼ƒæ¶ˆæ¯
		h.logger.Warn("âš ï¸ æ¶ˆæ¯å¤„ç†é˜Ÿåˆ—æ»¡ï¼Œä¸¢å¼ƒæ¶ˆæ¯",
			zap.String("user_id", userID),
			zap.Int("queue_size", len(h.queue)),
			zap.Int("max_queue_size", h.queueSize),
		)
		atomic.AddInt64(&h.droppedCount, 1)

		// âœ… å½’è¿˜åˆ°æ± ï¼ˆå¯¹æ ‡ Netty ReferenceCountUtil.release()ï¼‰
		messageTaskPool.Put(task)

		// è®°å½•ç›‘æ§æŒ‡æ ‡
		if h.metricsClient != nil {
			// h.metricsClient.RecordMessageDropped()
		}

		return false
	}
}

// MessageWorker.run å·¥ä½œåç¨‹ä¸»å¾ªç¯
func (w *MessageWorker) run(wg *sync.WaitGroup, handler *AsyncMessageHandler) {
	defer wg.Done()

	for task := range w.queue {
		startTime := time.Now()

		// è°ƒç”¨åŸå§‹ MessageHandler å¤„ç†
		if err := w.handler.HandleBinaryMessage(task.Connection, task.Message); err != nil {
			w.logger.Error("æ¶ˆæ¯å¤„ç†å¤±è´¥",
				zap.String("user_id", task.UserID),
				zap.Int("message_size", len(task.Message)),
				zap.Duration("duration", time.Since(startTime)),
				zap.Error(err),
			)
			atomic.AddInt64(&handler.failureCount, 1)

			// è®°å½•å¤±è´¥ç›‘æ§
			if w.metrics != nil {
				// w.metrics.RecordMessageProcessingFailed()
			}
		} else {
			w.logger.Debug("æ¶ˆæ¯å¤„ç†æˆåŠŸ",
				zap.String("user_id", task.UserID),
				zap.Int("message_size", len(task.Message)),
				zap.Duration("duration", time.Since(startTime)),
			)
			atomic.AddInt64(&handler.processedCount, 1)

			// è®°å½•æˆåŠŸç›‘æ§
			if w.metrics != nil {
				// w.metrics.RecordMessageProcessingSuccess(time.Since(startTime))
			}
		}

		// ç´¯è®¡å¤„ç†æ—¶é—´
		atomic.AddInt64(&handler.processingTime, time.Since(startTime).Nanoseconds())

		// âœ… å½’è¿˜åˆ°æ± ï¼ˆå¯¹æ ‡ Netty ReferenceCountUtil.release()ï¼‰
		messageTaskPool.Put(task)
	}
}

// WaitUntilEmpty ç­‰å¾…é˜Ÿåˆ—ä¸ºç©ºï¼ˆç”¨äºä¼˜é›…å…³é—­ï¼‰
func (h *AsyncMessageHandler) WaitUntilEmpty(timeout time.Duration) bool {
	deadline := time.Now().Add(timeout)
	ticker := time.NewTicker(100 * time.Millisecond)
	defer ticker.Stop()

	for {
		if len(h.queue) == 0 {
			return true
		}

		select {
		case <-ticker.C:
			if time.Now().After(deadline) {
				h.logger.Warn("ç­‰å¾…æ¶ˆæ¯é˜Ÿåˆ—æ¸…ç©ºè¶…æ—¶",
					zap.Int("remaining_messages", len(h.queue)),
				)
				return false
			}
		}
	}
}

// Shutdown å…³é—­å¼‚æ­¥å¤„ç†å™¨
func (h *AsyncMessageHandler) Shutdown(ctx context.Context) {
	h.logger.Info("ğŸ”„ å…³é—­å¼‚æ­¥æ¶ˆæ¯å¤„ç†å™¨...")

	// ç­‰å¾…é˜Ÿåˆ—ä¸­çš„ä»»åŠ¡å¤„ç†å®Œ
	h.WaitUntilEmpty(30 * time.Second)

	// å…³é—­é˜Ÿåˆ—ï¼Œé€šçŸ¥æ‰€æœ‰å·¥ä½œåç¨‹åœæ­¢
	close(h.queue)

	// ç­‰å¾…æ‰€æœ‰å·¥ä½œåç¨‹ç»“æŸ
	h.wg.Wait()

	h.logger.Info("âœ… å¼‚æ­¥æ¶ˆæ¯å¤„ç†å™¨å·²å…³é—­",
		zap.Int64("processed", atomic.LoadInt64(&h.processedCount)),
		zap.Int64("dropped", atomic.LoadInt64(&h.droppedCount)),
		zap.Int64("failures", atomic.LoadInt64(&h.failureCount)),
		zap.Int("max_queue_length", h.queueMaxLength),
	)
}

// GetStats è·å–ç»Ÿè®¡ä¿¡æ¯
func (h *AsyncMessageHandler) GetStats() map[string]interface{} {
	h.mu.RLock()
	defer h.mu.RUnlock()

	totalProcessed := atomic.LoadInt64(&h.processedCount)
	avgProcessingTime := int64(0)
	if totalProcessed > 0 {
		avgProcessingTime = atomic.LoadInt64(&h.processingTime) / totalProcessed
	}

	return map[string]interface{}{
		"processed_count":        totalProcessed,
		"dropped_count":          atomic.LoadInt64(&h.droppedCount),
		"failure_count":          atomic.LoadInt64(&h.failureCount),
		"current_queue_len":      len(h.queue),
		"max_queue_length":       h.queueMaxLength,
		"num_workers":            h.numWorkers,
		"queue_size":             h.queueSize,
		"avg_processing_time_ms": avgProcessingTime / 1_000_000,
	}
}

// GetQueueLength è·å–å½“å‰é˜Ÿåˆ—é•¿åº¦
func (h *AsyncMessageHandler) GetQueueLength() int {
	return len(h.queue)
}

// GetSuccessRate è·å–æˆåŠŸç‡
func (h *AsyncMessageHandler) GetSuccessRate() float64 {
	total := atomic.LoadInt64(&h.processedCount) + atomic.LoadInt64(&h.droppedCount) + atomic.LoadInt64(&h.failureCount)
	if total == 0 {
		return 1.0
	}
	return float64(atomic.LoadInt64(&h.processedCount)) / float64(total)
}
